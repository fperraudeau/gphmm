---
title: "Vignette gphmm"
author: "Fanny Perraudeau"
date: "04/26/2017"
output: 
  html_document: 
    fig_height: 10
    fig_width: 10
    toc: yes
    code_folding: hide
    toc_float: yes
---

```{r options, echo=FALSE, results="hide",message=FALSE, error=FALSE, include=FALSE, autodep=TRUE}
knitr::opts_chunk$set(fig.align="center", cache=FALSE, error=FALSE, message=FALSE, warning=TRUE)
library(gphmm)
library(jsonlite)
library(Biostrings)
```

#1. Commandline tool

```{bash}
../inst/gphmm --help
```

There are two ways to use the command line tool. You can compute the GPHMM probabilities using a set of parameters or train the model to estimate the parameters using noisy reads and the non noisy version of the sequences.


When gphmm compute is used, the two main inputs are  

* a fasta file with the DNA sequences for all the sequences you want to compute the GPHMM probabilities for,  
* a csv file with at least two columns
    - a first column with the name of the queries,  
    - a second column with the name of the reference sequences,
    - optionally, a third column with the quality values of the queries. If not specified, a quality value of 20 is used by default.  
  
The name of the queries and reference sequences in the csv file should have a sequence with the same name in the fasta file. Then, for each row in the csv file, the GPHMM probability is comppute for the corresponding query and reference sequence.

#2. Compute

Let's see how to compute GPHMM probabilities.


## Pick parameters
To compute the GPHMM probabilities, we need GPHMM parameters. We can use the last version of the gphmm parameters in the directory training of the gphmm (default).
```{r}
paramgphmm = fromJSON(findLastJson())
paramgphmm
```

Alternatively, you can use the GPHMM parameters used during the initialization of the GPHMM training
```{r}
paramgphmm = initializeGphmm()
paramgphmm
```

## Use R functions
Let's compute the GPHMM probability (actually the log of the GPHMM probability) for the two following sequences   

Query  
```{r}
read = 'ATGCGATGCA'
read
```

Reference sequence
```{r}
ref = 'ATGTACGATGA'
ref
```

GPHMM probability
```{r}
computegphmm(read = read,
             ref = ref,
             parameters = paramgphmm,
             output = "short")
```

You can also look at the long output to look at the path 
```{r}
computegphmm(read = read,
             ref =  ref,
             parameters = paramgphmm,
             output = "long")
```
Note that 'M' means Match or Mismatch.


## Use commandline
```{r}
n = 100
```

Let's randomly generate `r n` sequences
```{r}
seqs = generateRandomSequences(n = n, meanLen = 100, sdLen = 2,
                               seed = 7373)
writeXStringSet(seqs, 'queries.fasta')
seqs
```

We are going to compute GPHMM for all pairs of sequences. We did not include a column for the quality values, so a quality value of 20 is used.
```{r}
toCompute = data.frame(query = rep(paste0('s', 1:n), n),
                       ref = rep(paste0('s', 1:n), each = n))
write.table(toCompute, 'toCompute.csv')
head(toCompute)
```

So, there are `r nrow(toCompute)` GPHMM probabilities to compute. Let's call the commandline tool gphmm compute
```{bash}
../inst/gphmm compute queries.fasta toCompute.csv --verbose
```

The output file is the same as the csv file, but a column has been added for the computed GPHMM probabilities 
```{r}
out = read.table('toCompute_gphmm.csv', stringsAsFactors = F)
head(out)
```


# 3.Train

The GPHMM is a generative model. Therefore, we can generate reads from sequences using our GPHMM model and a set of chosen parameters. Then, we can estimate the parameters using our model. In real life, you would never know the true parameters. We would need sequences where you need the true sequences and the noisy version of the sequences.


## Generate training set
```{r}
n = 50
```

We choose the following set of parameters
```{r}
paramgphmm = initializeGphmm()
paramgphmm
```

We randomly generate `r n` sequences. Note that you need more sequences to estimate unbiased parameters, but for this vignette we use a small number of sequences to reduce the computation time.
```{r}
seqs = generateRandomSequences(n = n, meanLen = 100, sdLen = 5,
                               prob = paramgphmm$qR, seed = 7373)
seqs
```

Let's now introduce errors in our sequences
```{r}
qv = rnorm(n, 20, 5)
qv[qv < 5] = 5
reads = mclapply(1:n, function(i){
  generateRead(seq = as.character(seqs[i]), paramgphmm = paramgphmm,
                qv = qv[i], seed = i)
}, mc.cores = 2)
train = c(seqs, DNAStringSet(sapply(reads, '[[', 1)))
names(train) = c(names(train)[1:n], gsub('s', 't', names(train)[1:n]))
csv = data.frame(reads = paste0('t', 1:n), ref = paste0('s', 1:n), qv = qv)

# write files
writeXStringSet(train, 'train.fasta')
write.table(csv, 'train.csv')
```

```{r}
plot(density(qv), main = 'Quality value of the reads (Phred score)')
```

```{r}
par(mfrow=c(1,2))
plot(density(width(seqs)), main = 'Length of the sequences')
plot(density(width(train[grepl('t', names(train))])), main = 'Length of the reads')
par(mfrow=c(1,2))
```

The true counts for the emission and transition matrices are
```{r}
emiTrans = lapply(reads, function(x) computeCounts(x)) 
emiTrans = lapply(lapply(c(1:4), function(i) lapply(emiTrans, '[[', i)), function(x) Reduce('+', x))
names(emiTrans) = c('counts_emissionM', 'counts_emissionD',
                    'counts_emissionI', 'counts_transition')
emiTrans
```

## Run commandline
```{bash}
../inst/gphmm train train.fasta train.csv --verbose --maxit=5
```

## Evaluate
The estimates are
```{r}
estimator = fromJSON('train_paramgphmm.json')
estimator
```

And the log likelihood at each iteration of the training procedure
```{r}
ll = fromJSON('train_llgphmm.json')
plot(1:length(ll), ll, xlab = 'Iterations', ylab = 'Log Likelihood',
     type = 'l', main = 'Log likelihood')
```

```{r}
plot(unlist(mapply('-', estimator, paramgphmm, SIMPLIFY = FALSE)),
     main = 'Bias for each parameter', xlab = 'Parameter', ylab = 'Bias')
abline(h = 0)
```

Parameters where the bias is high are the deltas....
```{r}
par(mfrow = c(1,2))
qv = seq(1, 40, length.out = 100)
insEstim = sapply(qv, function(x) 1/(1+exp(-sum(estimator$deltaX * c(1, x)))))
insTrue = sapply(qv, function(x) 1/(1+exp(-sum(paramgphmm$deltaX * c(1, x)))))
delEstim = sapply(qv, function(x) 1/(1+exp(-sum(estimator$deltaY * c(1, x)))))
delTrue = sapply(qv, function(x) 1/(1+exp(-sum(paramgphmm$deltaY * c(1, x)))))
plot(qv, insEstim, col = 'blue', type = 'l', ylab = 'Insertion rate')
lines(qv, insTrue, col = 'red')
plot(qv, delEstim, col = 'blue', type = 'l', ylab = 'Deletion rate')
lines(qv, delTrue, col = 'red')
```


```{r}
# remove generated files
system('rm queries.fasta')
system('rm toCompute_gphmm.csv')
system('rm toCompute.csv')
system('rm train.csv')
system('rm train.fasta')
system('rm train_paramgphmm.json')
system('rm train_llgphmm.json')
```
